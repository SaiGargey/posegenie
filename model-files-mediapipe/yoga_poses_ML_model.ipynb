{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS USED TO CALCULATE ANGLES\n",
    "\n",
    "def calculate_angle(point1,point2,point3):\n",
    "    a = np.array(point1) #First\n",
    "    b = np.array(point2) #Mid\n",
    "    c = np.array(point3) #End\n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle \n",
    "    \n",
    "def angle_of_singleline(point1, point2):\n",
    "    \"\"\" Calculate angle of a single line \"\"\"\n",
    "    x_diff = point2[0] - point1[0]\n",
    "    y_diff = point2[1] - point1[1]\n",
    "    return math.degrees(math.atan2(y_diff, x_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RETRIEVES DETECTED LANDMARDS AND RESULTS USING MEDIA PIPE\n",
    "\n",
    "def apply_detection_to_image(file):\n",
    "    #import cv2\n",
    "    pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "    sample_img = cv2.imread(file)\n",
    "    results = pose.process(cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB))\n",
    "    landmarks = results.pose_landmarks.landmark\n",
    "    return landmarks, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USES MEDIAPIPE LANDMARKS TO CALCULATE ANGLES\n",
    "\n",
    "def get_pose_landmarks(landmarks):\n",
    "    # GET COORDINATES OF JOINTS\n",
    "    left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "    left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "    left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "\n",
    "    left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "    left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "    left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "\n",
    "    right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "    right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "    right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "\n",
    "    right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "    right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "    right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "      # CALCULATE SOME REQUIRED METRICS ANGLES\n",
    "\n",
    "    left_elbow_angle = np.round(calculate_angle(left_shoulder,left_elbow,left_wrist))\n",
    "    left_elbow_angle_hor = np.round(angle_of_singleline(left_elbow,left_wrist))\n",
    "    left_knee_angle = np.round(calculate_angle(left_hip, left_knee, left_ankle))\n",
    "    left_knee_angle_ver = np.round(angle_of_singleline(left_knee,left_ankle))\n",
    "    left_hip_angle = np.round(calculate_angle(left_shoulder,left_hip, left_knee))\n",
    "\n",
    "    right_elbow_angle = np.round(calculate_angle(right_shoulder,right_elbow,right_wrist))\n",
    "    right_elbow_angle_hor = np.round(angle_of_singleline(right_wrist,right_elbow))\n",
    "    right_knee_angle = np.round(calculate_angle(right_hip, right_knee, right_ankle))\n",
    "    right_knee_angle_ver = np.round(angle_of_singleline(right_knee,right_ankle))\n",
    "    right_hip_angle = np.round(calculate_angle(right_shoulder,right_hip, right_knee))\n",
    "\n",
    "    return left_elbow_angle, left_elbow_angle_hor, left_knee_angle, left_knee_angle_ver, left_hip_angle, right_elbow_angle, right_elbow_angle_hor, right_knee_angle, right_knee_angle_ver, right_hip_angle\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OF IMAGE WITH SUPERIMPOSED LANDMARSK FOR QUALITY CHECK\n",
    "\n",
    "def plot_figure(file, results):\n",
    "    #pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "    sample_img = cv2.imread(file)\n",
    "\n",
    "    img_copy = sample_img.copy()\n",
    "\n",
    "    # Draw Pose landmarks on the sample image.\n",
    "    mp_drawing.draw_landmarks(image=img_copy, landmark_list=results.pose_landmarks, connections=mp_pose.POSE_CONNECTIONS)\n",
    "       \n",
    "    # Specify a size of the figure.\n",
    "    fig = plt.figure(figsize = [10, 10])\n",
    " \n",
    "    # Display the output image with the landmarks drawn, also convert BGR to RGB for display. \n",
    "    plt.title(\"Output\");plt.axis('off');plt.imshow(img_copy[:,:,::-1]);plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA TRAINING READING ROUTINE (works for jpg, png)\n",
    "# EXPECTS following structure:\n",
    "# in folder /google_images/ there is one folder per yoga pose. For example, feft_warrior2, right_warrior2\n",
    "# google_images/left_warrior2\n",
    "# google_images/right_warrior2\n",
    "# in each folder, there are images showing the pose\n",
    "# this script reads each image, gets the landmarks with mediapie, calculate angles\n",
    "\n",
    "image_dir = 'google_images/'\n",
    "pose_examples = os.listdir(image_dir)\n",
    "pose_images = {}\n",
    "pose_all_data = []\n",
    "pose_label = []\n",
    "pose_data = []\n",
    "for poses in pose_examples:\n",
    "    file_list =  os.listdir(image_dir + poses)\n",
    "    pose_images[poses]=file_list\n",
    "\n",
    "pose_number = 0\n",
    "for key in pose_images:\n",
    "    for file in pose_images[key]:\n",
    "        file_path = image_dir + key + '/' + file\n",
    "        #print(file_path)\n",
    "        landmarks0, results0 = apply_detection_to_image(file_path)\n",
    "        markers0 = get_pose_landmarks(landmarks0)\n",
    "        pose_all_data.append([key, pose_number, file_path,  markers0])\n",
    "        pose_data.append(markers0)\n",
    "        pose_label.append(pose_number)\n",
    "        #plot_figure(file_path, results0)\n",
    "    pose_number = pose_number + 1\n",
    "pose_data_np = np.array(pose_data)\n",
    "pose_label_np = np.array(pose_label)\n",
    "\n",
    "#left_elbow_angle, left_elbow_angle_hor, left_knee_angle, left_knee_angle_ver, left_hip_angle, right_elbow_angle, right_elbow_angle_hor, right_knee_angle, right_knee_angle_ver, right_hip_angle\n",
    "features_str = [\"left_elbow_angle\", \"left_elbow_angle_hor\", \"left_knee_angle\", \"left_knee_angle_ver\", \"left_hip_angle\", \"right_elbow_angle\", \"right_elbow_angle_hor\", \"right_knee_angle\", \"right_knee_angle_ver\", \"right_hip_angle\"]\n",
    "pose_names_str = pose_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_names_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE CLASSIFIER TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import pickle\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pose_data_np, pose_label_np, random_state = 2)\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "filename1 = 'yoga_poses_decisiontree.model'\n",
    "filename2 = 'yoga_poses_decisiontree.labels'\n",
    "pickle.dump(clf, open(filename1, 'wb'))\n",
    "pickle.dump(pose_names_str, open(filename2,'wb'))\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT THESE LINES TO PLOT A FIGURE\n",
    "\n",
    "#fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (10,10), dpi=150)\n",
    "#plot_tree(clf, feature_names=features_str, class_names=pose_names_str, filled=True, fontsize=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST THE CODE WITH NEW IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label:  0\n",
      "Label corresponds to pose:  left_tree\n"
     ]
    }
   ],
   "source": [
    "file_path = \"unseen_images/left_tree.jpg\"\n",
    "landmarks0, results0 = apply_detection_to_image(file_path)\n",
    "markers0 = np.array(get_pose_landmarks(landmarks0)).reshape(1, -1)\n",
    "markers0\n",
    "\n",
    "# GET PREDICTION\n",
    "predict_label = (clf.predict(markers0))\n",
    "print(\"Predicted label: \", predict_label[0])\n",
    "print(\"Label corresponds to pose: \", pose_names_str[predict_label[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_names_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60df1b10d45d0935aa24c18b5ed04989de2fdfd1b656f00329688cd3ff4f4860"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
