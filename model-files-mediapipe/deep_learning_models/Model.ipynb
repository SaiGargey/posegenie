{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c015344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import enum\n",
    "from typing import List, NamedTuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0788abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BodyPart(enum.Enum):\n",
    "  \"\"\"Enum representing human body keypoints detected by pose estimation models.\"\"\"\n",
    "  NOSE = 0\n",
    "  LEFT_EYE = 1\n",
    "  RIGHT_EYE = 2\n",
    "  LEFT_EAR = 3\n",
    "  RIGHT_EAR = 4\n",
    "  LEFT_SHOULDER = 5\n",
    "  RIGHT_SHOULDER = 6\n",
    "  LEFT_ELBOW = 7\n",
    "  RIGHT_ELBOW = 8\n",
    "  LEFT_WRIST = 9\n",
    "  RIGHT_WRIST = 10\n",
    "  LEFT_HIP = 11\n",
    "  RIGHT_HIP = 12\n",
    "  LEFT_KNEE = 13\n",
    "  RIGHT_KNEE = 14\n",
    "  LEFT_ANKLE = 15\n",
    "  RIGHT_ANKLE = 16\n",
    "\n",
    "\n",
    "class Point(NamedTuple):\n",
    "  \"\"\"A point in 2D space.\"\"\"\n",
    "  x: float\n",
    "  y: float\n",
    "\n",
    "\n",
    "class Rectangle(NamedTuple):\n",
    "  \"\"\"A rectangle in 2D space.\"\"\"\n",
    "  start_point: Point\n",
    "  end_point: Point\n",
    "\n",
    "\n",
    "class KeyPoint(NamedTuple):\n",
    "  \"\"\"A detected human keypoint.\"\"\"\n",
    "  body_part: BodyPart\n",
    "  coordinate: Point\n",
    "  score: float\n",
    "\n",
    "\n",
    "class Person(NamedTuple):\n",
    "  \"\"\"A pose detected by a pose estimation model.\"\"\"\n",
    "  keypoints: List[KeyPoint]\n",
    "  bounding_box: Rectangle\n",
    "  score: float\n",
    "  id: int = None\n",
    "\n",
    "\n",
    "def person_from_keypoints_with_scores(\n",
    "    keypoints_with_scores: np.ndarray,\n",
    "    image_height: float,\n",
    "    image_width: float,\n",
    "    keypoint_score_threshold: float = 0.1) -> Person:\n",
    "  \"\"\"Creates a Person instance from single pose estimation model output.\n",
    "  Args:\n",
    "    keypoints_with_scores: Output of the TFLite pose estimation model. A numpy\n",
    "      array with shape [17, 3]. Each row represents a keypoint: [y, x, score].\n",
    "    image_height: height of the image in pixels.\n",
    "    image_width: width of the image in pixels.\n",
    "    keypoint_score_threshold: Only use keypoints with above this threshold to\n",
    "      calculate the person average score.\n",
    "  Returns:\n",
    "    A Person instance.\n",
    "  \"\"\"\n",
    "\n",
    "  kpts_x = keypoints_with_scores[:, 1]\n",
    "  kpts_y = keypoints_with_scores[:, 0]\n",
    "  scores = keypoints_with_scores[:, 2]\n",
    "\n",
    "  # Convert keypoints to the input image coordinate system.\n",
    "  keypoints = []\n",
    "  for i in range(scores.shape[0]):\n",
    "    keypoints.append(\n",
    "        KeyPoint(\n",
    "            BodyPart(i),\n",
    "            Point(int(kpts_x[i] * image_width), int(kpts_y[i] * image_height)),\n",
    "            scores[i]))\n",
    "\n",
    "  # Calculate bounding box as SinglePose models don't return bounding box.\n",
    "  start_point = Point(\n",
    "      int(np.amin(kpts_x) * image_width), int(np.amin(kpts_y) * image_height))\n",
    "  end_point = Point(\n",
    "      int(np.amax(kpts_x) * image_width), int(np.amax(kpts_y) * image_height))\n",
    "  bounding_box = Rectangle(start_point, end_point)\n",
    "\n",
    "  # Calculate person score by averaging keypoint scores.\n",
    "  scores_above_threshold = list(\n",
    "      filter(lambda x: x > keypoint_score_threshold, scores))\n",
    "  person_score = np.average(scores_above_threshold)\n",
    "\n",
    "  return Person(keypoints, bounding_box, person_score)\n",
    "\n",
    "\n",
    "class Category(NamedTuple):\n",
    "  \"\"\"A classification category.\"\"\"\n",
    "  label: str\n",
    "  score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895b885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading final csv file\n",
    "def load_csv(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.drop(['filename'],axis=1, inplace=True)\n",
    "    classes = df.pop('class_name').unique()\n",
    "    y = df.pop('class_no')\n",
    "    \n",
    "    X = df.astype('float64')\n",
    "    y = keras.utils.to_categorical(y)\n",
    "    \n",
    "    return X, y, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1141bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_point(landmarks, left_bodypart, right_bodypart):\n",
    "    \"\"\"Calculates the center point of the two given landmarks.\"\"\"\n",
    "    left = tf.gather(landmarks, left_bodypart.value, axis=1)\n",
    "    right = tf.gather(landmarks, right_bodypart.value, axis=1)\n",
    "    center = left * 0.5 + right * 0.5\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b65b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pose_size(landmarks, torso_size_multiplier=2.5):\n",
    "    \"\"\"Calculates pose size.\n",
    "    It is the maximum of two values:\n",
    "    * Torso size multiplied by `torso_size_multiplier`\n",
    "    * Maximum distance from pose center to any pose landmark\n",
    "    \"\"\"\n",
    "    # Hips center\n",
    "    hips_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "\n",
    "    # Shoulders center\n",
    "    shoulders_center = get_center_point(landmarks, BodyPart.LEFT_SHOULDER,\n",
    "                                      BodyPart.RIGHT_SHOULDER)\n",
    "\n",
    "    # Torso size as the minimum body size\n",
    "    torso_size = tf.linalg.norm(shoulders_center - hips_center)\n",
    "    # Pose center\n",
    "    pose_center_new = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                     BodyPart.RIGHT_HIP)\n",
    "    pose_center_new = tf.expand_dims(pose_center_new, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to\n",
    "    # perform substraction\n",
    "    pose_center_new = tf.broadcast_to(pose_center_new,\n",
    "                                    [tf.size(landmarks) // (17*2), 17, 2])\n",
    "\n",
    "    # Dist to pose center\n",
    "    d = tf.gather(landmarks - pose_center_new, 0, axis=0,\n",
    "                name=\"dist_to_pose_center\")\n",
    "    # Max dist to pose center\n",
    "    max_dist = tf.reduce_max(tf.linalg.norm(d, axis=0))\n",
    "\n",
    "    # Normalize scale\n",
    "    pose_size = tf.maximum(torso_size * torso_size_multiplier, max_dist)\n",
    "    return pose_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e38cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pose_landmarks(landmarks):\n",
    "    \"\"\"Normalizes the landmarks translation by moving the pose center to (0,0) and\n",
    "    scaling it to a constant pose size.\n",
    "  \"\"\"\n",
    "  # Move landmarks so that the pose center becomes (0,0)\n",
    "    pose_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n",
    "                                 BodyPart.RIGHT_HIP)\n",
    "\n",
    "    pose_center = tf.expand_dims(pose_center, axis=1)\n",
    "    # Broadcast the pose center to the same size as the landmark vector to perform\n",
    "    # substraction\n",
    "    pose_center = tf.broadcast_to(pose_center, \n",
    "                                [tf.size(landmarks) // (17*2), 17, 2])\n",
    "    landmarks = landmarks - pose_center\n",
    "\n",
    "    # Scale the landmarks to a constant pose size\n",
    "    pose_size = get_pose_size(landmarks)\n",
    "    landmarks /= pose_size\n",
    "    return landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "473f6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmarks_to_embedding(landmarks_and_scores):\n",
    "    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n",
    "    # Reshape the flat input into a matrix with shape=(17, 3)\n",
    "    reshaped_inputs = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n",
    "\n",
    "    # Normalize landmarks 2D\n",
    "    landmarks = normalize_pose_landmarks(reshaped_inputs[:, :, :2])\n",
    "    # Flatten the normalized landmark coordinates into a vector\n",
    "    embedding = keras.layers.Flatten()(landmarks)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a50993cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_train):\n",
    "    processed_X_train = []\n",
    "    for i in range(X_train.shape[0]):\n",
    "        embedding = landmarks_to_embedding(tf.reshape(tf.convert_to_tensor(X_train.iloc[i]), (1, 51)))\n",
    "        processed_X_train.append(tf.reshape(embedding, (34)))\n",
    "    return tf.convert_to_tensor(processed_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e402c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    '''\n",
    "    Halts the training after reaching 97 percent validation accuracy\n",
    "\n",
    "    Args:\n",
    "      epoch (integer) - index of epoch (required but unused in the function definition below)\n",
    "      logs (dict) - metric results from the training epoch\n",
    "    '''\n",
    "\n",
    "    # Check accuracy\n",
    "    if(logs.get('val_accuracy') > 0.97):\n",
    "\n",
    "      # Stop if threshold is met\n",
    "      print(\"\\accuracy is higher than 0.99 so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "# Instantiate class\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, class_names = load_csv('train_data.csv')\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15)\n",
    "X_test, y_test, _ = load_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba235a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_X_train = preprocess_data(X_train)\n",
    "processed_X_val =  preprocess_data(X_val)\n",
    "processed_X_test = preprocess_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ce6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model layers\n",
    "inputs = tf.keras.Input(shape=(processed_X_train.shape[1]))\n",
    "# Adding Conv layers resulted in slightly worse accuracy\n",
    "#layer = keras.layers.Conv1D(16, kernel_size=3, activation=tf.nn.relu6)(inputs)\n",
    "#layer = keras.layers.MaxPooling1D(2)(layer)\n",
    "#layer = keras.layers.Flatten()(layer)\n",
    "layer = keras.layers.Dense(128, activation=tf.nn.relu6)(inputs)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "layer = keras.layers.Dense(64, activation=tf.nn.relu6)(layer)\n",
    "layer = keras.layers.Dropout(0.5)(layer)\n",
    "outputs = keras.layers.Dense(len(class_names), activation=\"softmax\")(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e3c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2155e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9d755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print('--------------TRAINING----------------')\n",
    "history = model.fit(processed_X_train, y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(processed_X_val, y_val),\n",
    "                    callbacks=callbacks)\n",
    "print('-----------------EVAUATION----------------')\n",
    "loss, accuracy = model.evaluate(processed_X_test, y_test)\n",
    "print('LOSS: ', loss)\n",
    "print(\"ACCURACY: \", accuracy)\n",
    "#model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
